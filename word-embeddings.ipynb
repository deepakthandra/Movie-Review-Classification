{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Classification with Word Embeddings (Feb 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from spacy.symbols import ORTH\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"aclImdb/\"\n",
    "names = ['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!"
     ]
    }
   ],
   "source": [
    "!head $path/train/pos/0_9.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts,labels = [],[]\n",
    "for idx,label in enumerate(names):\n",
    "    for fname in glob.glob(os.path.join(f'{path}train', label, '*.*')):\n",
    "        texts.append(open(fname, 'r').read())\n",
    "        labels.append(idx)\n",
    "trn,trn_y= texts, np.array(labels).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts,labels = [],[]\n",
    "for idx,label in enumerate(names):\n",
    "    for fname in glob.glob(os.path.join(f'{path}test', label, '*.*')):\n",
    "        texts.append(open(fname, 'r').read())\n",
    "        labels.append(idx)\n",
    "test,test_y= texts, np.array(labels).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use the libary spacy to tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# borrowed from fast.ai (https://github.com/fastai/fastai/blob/master/fastai/nlp.py)\n",
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'lacked',\n",
       " 'something',\n",
       " 'i',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'put',\n",
       " 'my',\n",
       " 'finger',\n",
       " 'on',\n",
       " 'at',\n",
       " 'first',\n",
       " ':',\n",
       " 'charisma',\n",
       " 'on',\n",
       " 'the',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'leading',\n",
       " 'actress',\n",
       " '.',\n",
       " 'this',\n",
       " 'inevitably',\n",
       " 'translated',\n",
       " 'to',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'chemistry',\n",
       " 'when',\n",
       " 'she',\n",
       " 'shared',\n",
       " 'the',\n",
       " 'screen',\n",
       " 'with',\n",
       " 'her',\n",
       " 'leading',\n",
       " 'man',\n",
       " '.',\n",
       " 'even',\n",
       " 'the',\n",
       " 'romantic',\n",
       " 'scenes',\n",
       " 'came',\n",
       " 'across',\n",
       " 'as',\n",
       " 'being',\n",
       " 'merely',\n",
       " 'the',\n",
       " 'actors',\n",
       " 'at',\n",
       " 'play',\n",
       " '.',\n",
       " 'it',\n",
       " 'could',\n",
       " 'very',\n",
       " 'well',\n",
       " 'have',\n",
       " 'been',\n",
       " 'the',\n",
       " 'director',\n",
       " 'who',\n",
       " 'miscalculated',\n",
       " 'what',\n",
       " 'he',\n",
       " 'needed',\n",
       " 'from',\n",
       " 'the',\n",
       " 'actors',\n",
       " '.',\n",
       " 'i',\n",
       " 'just',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'but',\n",
       " 'could',\n",
       " 'it',\n",
       " 'have',\n",
       " 'been',\n",
       " 'the',\n",
       " 'screenplay',\n",
       " '?',\n",
       " 'just',\n",
       " 'exactly',\n",
       " 'who',\n",
       " 'was',\n",
       " 'the',\n",
       " 'chef',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " '?',\n",
       " 'he',\n",
       " 'seemed',\n",
       " 'more',\n",
       " 'enamored',\n",
       " 'of',\n",
       " 'his',\n",
       " 'culinary',\n",
       " 'skills',\n",
       " 'and',\n",
       " 'restaurant',\n",
       " ',',\n",
       " 'and',\n",
       " 'ultimately',\n",
       " 'of',\n",
       " 'himself',\n",
       " 'and',\n",
       " 'his',\n",
       " 'youthful',\n",
       " 'exploits',\n",
       " ',',\n",
       " 'than',\n",
       " 'of',\n",
       " 'anybody',\n",
       " 'or',\n",
       " 'anything',\n",
       " 'else',\n",
       " '.',\n",
       " 'he',\n",
       " 'never',\n",
       " 'convinced',\n",
       " 'me',\n",
       " 'he',\n",
       " 'was',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " 'the',\n",
       " 'princess',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'i',\n",
       " 'was',\n",
       " 'disappointed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'movie',\n",
       " '.',\n",
       " 'but',\n",
       " ',',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'forget',\n",
       " 'it',\n",
       " 'was',\n",
       " 'nominated',\n",
       " 'for',\n",
       " 'an',\n",
       " 'oscar',\n",
       " ',',\n",
       " 'so',\n",
       " 'judge',\n",
       " 'for',\n",
       " 'yourself',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = trn[2]\n",
    "spacy_tok(row.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Non-Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get stop words\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modified from https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb\n",
    "def get_non_stopwords(review):\n",
    "    \"\"\"Returns a list of non-stopwords\"\"\"\n",
    "    return {x:1 for x in spacy_tok(str(review).lower()) if x not in stops}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['story', 'man', 'unnatural', 'feelings', 'pig', '.', 'starts', 'opening', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'turned', 'insane', ',', 'violent', 'mob', 'crazy', 'chantings', \"'s\", 'singers', 'unfortunately', 'stays', 'whole', 'time', 'general', 'narrative', 'eventually', 'making', 'putting', 'even', 'era', 'cryptic', 'dialogue', 'would', 'make', 'shakespeare', 'seem', 'easy', 'third', 'grader', 'technical', 'level', 'better', 'might', 'think', 'good', 'cinematography', 'future', 'great', 'vilmos', 'zsigmond', 'stars', 'sally', 'kirkland', 'frederic', 'forrest', 'seen', 'briefly'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_stopwords(trn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the 300 dimensional Glove embeddings into a dictionary.\n",
    "Globe embedings: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After downloading:\n",
    "globe_path = \"glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_word_embeddings(file=globe_path):\n",
    "    embeddings={}\n",
    "    with open(file,'r') as infile:\n",
    "        for line in infile:\n",
    "            values=line.split()\n",
    "            embeddings[values[0]]=np.asarray(values[1:],dtype='float32')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = load_word_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create average feature embedding for each sentence (stopwords ignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_features_v2(s, embeddings=embeddings,emb_size=300):\n",
    "    # ignore stop words\n",
    "    words=get_non_stopwords(s)\n",
    "    words=[w for w in words if w.isalpha() and w in embeddings]\n",
    "    if len(words)==0:\n",
    "        return np.hstack([np.zeros(emb_size)])\n",
    "    M=np.array([embeddings[w] for w in words])\n",
    "    return M.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = sentence_features_v2(trn[0])\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create sentence vectors\n",
    "x_train = np.array([sentence_features_v2(x) for x in trn])\n",
    "x_test = np.array([sentence_features_v2(x) for x in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 300), (25000, 300))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit an XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.679532\tvalid-logloss:0.681121\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.410523\tvalid-logloss:0.471239\n",
      "[100]\ttrain-logloss:0.327481\tvalid-logloss:0.421985\n",
      "[150]\ttrain-logloss:0.282652\tvalid-logloss:0.401021\n",
      "[200]\ttrain-logloss:0.252722\tvalid-logloss:0.390152\n",
      "[250]\ttrain-logloss:0.231107\tvalid-logloss:0.383067\n",
      "[300]\ttrain-logloss:0.213928\tvalid-logloss:0.378596\n",
      "[350]\ttrain-logloss:0.199011\tvalid-logloss:0.375209\n",
      "[399]\ttrain-logloss:0.187425\tvalid-logloss:0.373045\n"
     ]
    }
   ],
   "source": [
    "xgb_pars = {\"min_child_weight\": 50, \"eta\": 0.05, \"max_depth\": 8,\n",
    "            \"subsample\": 0.8, \"silent\" : 1, \"nthread\": 4,\n",
    "            \"eval_metric\": \"logloss\", \"objective\": \"binary:logistic\"}\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=trn_y)\n",
    "d_val = xgb.DMatrix(x_test, label=test_y)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_val, 'valid')]\n",
    "\n",
    "bst = xgb.train(xgb_pars, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fitting XGBoost to a one-hot encoding representation of the data with bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(tokenizer=nltk.word_tokenize,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_term_doc=veczr.fit_transform(trn)\n",
    "test_term_doc=veczr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 114215), (25000, 114215), (25000,), (25000,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape,test_term_doc.shape, trn_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.681228\tvalid-logloss:0.68133\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.4872\tvalid-logloss:0.494361\n",
      "[100]\ttrain-logloss:0.427427\tvalid-logloss:0.441414\n",
      "[150]\ttrain-logloss:0.392734\tvalid-logloss:0.411832\n",
      "[200]\ttrain-logloss:0.369056\tvalid-logloss:0.392905\n",
      "[250]\ttrain-logloss:0.351235\tvalid-logloss:0.380086\n",
      "[300]\ttrain-logloss:0.337678\tvalid-logloss:0.37019\n",
      "[350]\ttrain-logloss:0.326536\tvalid-logloss:0.362763\n",
      "[399]\ttrain-logloss:0.316882\tvalid-logloss:0.357108\n"
     ]
    }
   ],
   "source": [
    "xgb_pars = {\"min_child_weight\": 50, \"eta\": 0.05, \"max_depth\": 8,\n",
    "            \"subsample\": 0.8, \"silent\" : 1, \"nthread\": 4,\n",
    "            \"eval_metric\": \"logloss\", \"objective\": \"binary:logistic\"}\n",
    "\n",
    "d_train = xgb.DMatrix(trn_term_doc, label=trn_y)\n",
    "d_val = xgb.DMatrix(test_term_doc, label=test_y)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_val, 'valid')]\n",
    "\n",
    "bst = xgb.train(xgb_pars, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train loss, embedding method has a better result; but for validation loss,  the one-hot-encoding method has a better result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
